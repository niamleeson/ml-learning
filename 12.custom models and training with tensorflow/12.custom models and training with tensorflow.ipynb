{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    !pip install -U tqdm\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42) # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing\n",
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# math operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2] name: add/\n"
     ]
    }
   ],
   "source": [
    "# tf doesn't do type conversion automatically and instead it raises an exception\n",
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2] name: add/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.Tensor values are immutable\n",
    "# you need tf.Variable for mutable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strings\n",
    "tf.constant(b\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(p, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857]]>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>\n"
     ]
    }
   ],
   "source": [
    "# ragged tensors\n",
    "# list of tensors with same shape and data type\n",
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "print(tf.concat([r, r2], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101, 71], [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n"
     ]
    }
   ],
   "source": [
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
    "print(tf.concat([r, r3], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 7), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,    68,    69,    70],\n",
       "       [   67,   111,   102,   102,   101,   101,    71],\n",
       "       [   99,    97,   102,   102,   232,     0,     0],\n",
       "       [21654, 21857,    72,    73,     0,     0,     0]])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([r, r3], axis=1).to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse tensor\n",
    "# mostly zero tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                    values=[1., 2., 3.],\n",
    "                    dense_shape=[3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]],\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "print(s5)\n",
    "\n",
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 2,  3,  4,  5,  6,  7],\n",
       "       [ 0,  7,  9, 10,  0,  0]])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "tf.sparse.to_dense(tf.sets.union(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 3., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 3.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([4.6666665 8.666667 ], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
    "print(mean)\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.6247 - mae: 0.9969 - val_loss: 0.2884 - val_mae: 0.5913\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.2193 - mae: 0.5176 - val_loss: 0.2361 - val_mae: 0.5232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a5374b188>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and loading models with custom components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.7665 - mae: 0.9092 - val_loss: 0.6061 - val_mae: 0.6884\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2542 - mae: 0.5181 - val_loss: 0.4591 - val_mae: 0.6031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a52625cc8>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.HuberLoss"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HuberLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function: HuberLoss",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-33aba4ec3ee4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n\u001b[1;32m----> 2\u001b[1;33m                                custom_objects={\"HuberLoss\": HuberLoss})\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    144\u001b[0m   if (h5py is not None and (\n\u001b[0;32m    145\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Compile model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m       model.compile(**saving_utils.compile_args_from_training_config(\n\u001b[1;32m--> 184\u001b[1;33m           training_config, custom_objects))\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m       \u001b[1;31m# Set optimizer weights.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\saving\\saving_utils.py\u001b[0m in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    232\u001b[0m   \u001b[0mloss_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Deserialize loss class.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'class_name'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloss_config\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[0mloss_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m   loss = nest.map_structure(\n\u001b[0;32m    236\u001b[0m       lambda obj: custom_objects.get(obj, obj), loss_config)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\losses.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0midentifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\losses.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m   1173\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       printable_module_name='loss function')\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[1;32m--> 292\u001b[1;33m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'from_config'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[1;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unknown '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m   \u001b[0mcls_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown loss function: HuberLoss"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
    "                               custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.2392 - mae: 0.5038 - val_loss: 0.3717 - val_mae: 0.5594\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.2292 - mae: 0.4952 - val_loss: 0.2672 - val_mae: 0.4982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a57090348>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 1.4486 - mae: 0.8727 - val_loss: 2.4208 - val_mae: 0.5681\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.5848 - mae: 0.5260 - val_loss: 1.6040 - val_mae: 0.5122\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 1.4486 - mae: 0.8727 - val_loss: 2.4208 - val_mae: 0.5681\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.5848 - mae: 0.5260 - val_loss: 1.6040 - val_mae: 0.5122\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(1, activation=my_softplus,\n",
    "                           kernel_initializer=my_glorot_initializer,\n",
    "                           kernel_regularizer=my_l1_regularizer,\n",
    "                           kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer,\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 1.4486 - mae: 0.8727 - val_loss: 2.4208 - val_mae: 0.5681\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.5848 - mae: 0.5260 - val_loss: 1.6040 - val_mae: 0.5122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a587f7ec8>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"my_l1_regularizer\": my_l1_regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 1.4486 - mae: 0.8727 - val_loss: 2.4208 - val_mae: 0.5681\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.5848 - mae: 0.5260 - val_loss: 1.6040 - val_mae: 0.5122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a59b67588>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom metrics (different from loss)\n",
    "# metrics are used to evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 2.0326 - huber_fn: 0.9038\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 18us/sample - loss: 0.5862 - huber_fn: 0.2682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a587e2148>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can stream metrics as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/5\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: nan - val_loss: nan\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: nan - val_loss: nan\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: nan - val_loss: nan\n",
      "5160/5160 [==============================] - 0s 13us/sample - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stateful layer\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 2.1425 - val_loss: 1.2779\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.6367 - val_loss: 0.5267\n",
      "5160/5160 [==============================] - 0s 11us/sample - loss: 0.5359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5359284612559533"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_layer.h5\")\n",
    "\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_layer.h5\",\n",
    "                                custom_objects={\"MyDense\": MyDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer that takes 2 inputs and returns 3 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        return X1 + X2, X1 * X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer that behaves different during training and testing\n",
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4776 - val_loss: 0.5223\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.4213 - val_loss: 0.3807\n",
      "5160/5160 [==============================] - 0s 12us/sample - loss: 0.3977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39774652650189957"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_scaled = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z # add input to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/5\n",
      "11610/11610 [==============================] - 1s 77us/sample - loss: 11.4379\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 1.7623\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 1.4744\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.6444\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.5185\n",
      "5160/5160 [==============================] - 0s 25us/sample - loss: 0.6048\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jay\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: my_custom_model.ckpt\\assets\n",
      "Train on 11610 samples\n",
      "Epoch 1/5\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.6816\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.5100\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.6881\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.5656\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.7512\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_custom_model.ckpt\")\n",
    "\n",
    "model = keras.models.load_model(\"my_custom_model.ckpt\")\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/5\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.9281\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4480\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.7364\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.4003\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.5058\n",
      "5160/5160 [==============================] - 0s 22us/sample - loss: 0.4289\n"
     ]
    }
   ],
   "source": [
    "# sequential api can be used instead\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "block1 = ResidualBlock(2, 30)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    block1, block1, block1, block1,\n",
    "    ResidualBlock(2, 30),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and metric calculation based on weights or activations of hidden layers\n",
    "class ReconstructingRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        # TODO: check https://github.com/tensorflow/tensorflow/issues/26260\n",
    "        #self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        #if training:\n",
    "        #    result = self.reconstruction_mean(recon_loss)\n",
    "        #    self.add_metric(result)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 0.7648\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.4109\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# automatic gradient calculation with autodiff\n",
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2\n",
    "\n",
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with softmax, you may occasionally get NaN values\n",
    "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "x = tf.Variable([100.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([inf], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so what you need to do is use a decorator and make the function return\n",
    "# both a normal output and the function that computes the derivatives\n",
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradients(grad):\n",
    "        return grad / (1 + 1 / exp)\n",
    "    return tf.math.log(exp + 1), my_softplus_gradients\n",
    "\n",
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or alternatively, use tf.where() for large input\n",
    "def my_better_softplus(z):\n",
    "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))\n",
    "\n",
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/50 [>.............................] - loss: 1.0000 - mean_square: 1.0000"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-9508438fab5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmean_square\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint_status_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmean_square\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Layer dense_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "11610/11610 [==============================] - mean: 1.3955 - mean_absolute_error: 0.5722\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - mean: 0.6774 - mean_absolute_error: 0.5280\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - mean: 0.6351 - mean_absolute_error: 0.5177\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - mean: 0.6384 - mean_absolute_error: 0.5181\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - mean: 0.6440 - mean_absolute_error: 0.5222\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom layer that performs layer nomalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(keras.layers.Layer):\n",
    "    def __init__(self, eps=0.001, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(\n",
    "            name=\"alpha\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"ones\")\n",
    "        self.beta = self.add_weight(\n",
    "            name=\"beta\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        return self.alpha * (X - mean) / (tf.sqrt(variance + self.eps)) + self.beta\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"eps\": self.eps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.817434e-08>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train.astype(np.float32)\n",
    "\n",
    "custom_layer_norm = LayerNormalization()\n",
    "keras_layer_norm = keras.layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.1907103e-08>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_alpha = np.random.rand(X.shape[-1])\n",
    "random_beta = np.random.rand(X.shape[-1])\n",
    "\n",
    "custom_layer_norm.set_weights([random_alpha, random_beta])\n",
    "keras_layer_norm.set_weights([random_alpha, random_beta])\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training Fashion MNIST using custom training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255.\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff24859569464a33bf3dea926bf5a31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='All epochs', max=5, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1eb27d0ddd4d418500d18496c39a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1/5', max=1718, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc70716f92564179abf17113c3c54e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2/5', max=1718, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b575129a7554a21aa15fdb2b18b25ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3/5', max=1718, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59749095ec43465a8e05bbc4c0ccc07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4/5', max=1718, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c14879a735d4d34bc385733cbf739b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5/5', max=1718, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))                    \n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different optimizers with separate learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layers = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "])\n",
    "upper_layers = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model = keras.models.Sequential([\n",
    "    lower_layers, upper_layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_optimizer = keras.optimizers.SGD(lr=1e-4)\n",
    "upper_optimizer = keras.optimizers.Nadam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a1b03f5dbe475b8e14a35497e90ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='All epochs', max=5, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1588c698e21345ba9ed60d90fe9084c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1/5', max=1718, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76c62cc7aa6404eac2453223ff3efc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2/5', max=1718, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1684dff6534f4706a312400b76deba89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3/5', max=1718, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9256e5f3b43443f4ba2814440e53ede9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4/5', max=1718, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69aac674a01d491e8864f98efba6358a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5/5', max=1718, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                for layers, optimizer in ((lower_layers, lower_optimizer),\n",
    "                                          (upper_layers, upper_optimizer)):\n",
    "                    gradients = tape.gradient(loss, layers.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, layers.trainable_variables))\n",
    "                del tape\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))                    \n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
